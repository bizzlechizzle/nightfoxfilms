# Plan: CloudFront 403 Error Detection & Browser Session Sharing

**Issue:** CloudFront 403 error pages are being captured and stored as "extracted text" instead of being flagged as errors.

**Root Cause Analysis:**

---

## Problem 1: Text Extraction Doesn't Validate Content

**Current Flow:**
1. Puppeteer captures page → saves HTML file
2. Python `extract-text.py` extracts text from HTML file
3. Trafilatura/BeautifulSoup/Readability extract whatever text exists
4. Text is stored in database as `extracted_text`

**Gap:** Step 3 has **no content validation**. These libraries extract text blindly:
- Trafilatura → extracts the 403 error message as "article content"
- BeautifulSoup → extracts all visible text including error details
- Readability → treats error page as valid content

**The libraries don't care what the text says** — they just extract it.

---

## Problem 2: 403 Detection Exists But Has Gaps

**Current Detection (websource-orchestrator-service.ts:738-800):**
```typescript
if (responseStatus === 403) {
  const blockInfo = await this.detectBotBlock(page);
  // ... throws error if blocked
}
```

**Gaps:**
1. Detection runs at **capture time**, not text extraction time
2. If capture somehow "succeeds" (page loads with content), text extraction doesn't re-check
3. CloudFront 403s may return HTTP 200 with error content (soft block)
4. The `detectBotBlock()` patterns may not include all CloudFront error signatures

---

## Problem 3: Separate Browser Profiles

**Current Architecture:**
- **Research Browser**: Visible Ungoogled Chromium where user logs in
- **Archive Browser**: Headless Puppeteer with separate `archive-browser-profile`
- **Cookie Sync**: One-time sync from Research → Archive on first launch

**Issue:** User browses with Research Browser, gets authenticated sessions, but extraction uses Archive Browser which may not have the same session state, cookies, or auth tokens.

---

## Proposed Solution

### Fix 1: Post-Extraction Content Validation

Add error pattern detection **after** text extraction in Python script:

```python
ERROR_PATTERNS = [
    'request could not be satisfied',
    'cloudfront',
    '403 error',
    'access denied',
    'request blocked',
    'too much traffic',
    'configuration error',
    'generated by cloudfront',
]

def validate_extracted_text(text: str) -> tuple[bool, str]:
    """Check if extracted text is actually an error page."""
    text_lower = text.lower()
    for pattern in ERROR_PATTERNS:
        if pattern in text_lower:
            return False, f"Error page detected: {pattern}"
    return True, ""
```

**Files to modify:**
- `scripts/extract-text.py` — Add validation before returning results

### Fix 2: Enhanced CloudFront Detection in Orchestrator

Add CloudFront-specific patterns to `detectBotBlock()`:

```typescript
const CLOUDFRONT_PATTERNS = [
  'generated by cloudfront',
  'request could not be satisfied',
  'cloudfront request id',
  'there might be too much traffic',
];
```

**Files to modify:**
- `websource-orchestrator-service.ts` — Add to pattern list (~line 760)

### Fix 3: Use Same Browser Session (Research Browser Profile)

**Option A: Share Profile (Risk: Session Conflicts)**
- Point Archive Browser at Research Browser profile
- Risk: Simultaneous usage could corrupt profile

**Option B: Fresh Cookie Sync (Recommended)**
- Before each extraction, sync current cookies from Research Browser
- Preserves session isolation while getting fresh auth

**Option C: Use Research Browser Directly**
- For authenticated sites, launch visible Research Browser
- User sees the page load, we capture it
- More complex but guaranteed same session

**Recommended:** Option B with fallback to Option C for 403s.

**Files to modify:**
- `websource-capture-service.ts` — Add `syncCookiesBeforeCapture()` option
- `websource-orchestrator-service.ts` — Retry with fresh cookie sync on 403

---

## Implementation Steps

### Step 1: Add Error Pattern Detection to Python Extractor
1. Add `ERROR_PATTERNS` list with CloudFront and common error signatures
2. Add `validate_extracted_text()` function
3. Return `{"error": "...", "is_error_page": true}` instead of content when detected
4. TypeScript caller checks for error and marks web source as failed

### Step 2: Enhance Orchestrator Bot Detection
1. Add CloudFront-specific patterns to `detectBotBlock()`
2. Add Request ID detection (unique CloudFront signature)
3. Log detection reason for debugging

### Step 3: Add Fresh Cookie Sync Before Extraction
1. Add `syncCookiesFromResearchBrowser()` call before each capture
2. Only sync if Research Browser profile exists
3. Handle profile not found gracefully

### Step 4: Add 403 Retry with Research Browser Prompt
1. On 403/block detection, prompt user: "This site blocked automated access"
2. Offer: "Open in Research Browser to authenticate, then retry"
3. After user visits in Research Browser, retry extraction with fresh cookies

---

## Testing Checklist

- [ ] Capture CloudFront 403 page → Should fail with clear error message
- [ ] Capture CloudFlare challenge page → Should fail with clear error
- [ ] Capture page requiring auth → Should prompt for Research Browser
- [ ] Capture public page → Should succeed as before
- [ ] Cookie sync preserves logged-in state from Research Browser

---

## Files Summary

| File | Change |
|------|--------|
| `scripts/extract-text.py` | Add error pattern validation |
| `websource-orchestrator-service.ts` | Add CloudFront patterns, retry logic |
| `websource-capture-service.ts` | Add fresh cookie sync option |
| `websource-extraction-service.ts` | Check Python error response, mark as failed |

---

## Questions for User Review

1. **Cookie sync frequency:** Before every capture, or only on 403 retry?
2. **User prompt on 403:** Show UI dialog, or auto-retry silently first?
3. **Error page archival:** Should we still save the 403 HTML/screenshot for debugging, or skip entirely?
